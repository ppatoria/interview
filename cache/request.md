Attached is the code and results both for debug and release build. I want to create article based on my findings in blogging sites like LinkedIn and other sites. Can you please create a well formated article for me in markdown mode; even generate diagrams and images wherever required. Start with the 3 techniques we used for cache optimization i.e. (1) align data and align data structure (2) buffering (3) prefecting all the three have different variations in our testing and  mix of things but for a general overview just provide the base that what we tried to do. (2) regarding my findings (a) I found buffering is not efficient at least in correct scenario of our tests as  I think copy is involved (make clear that this is my assumption and I have not tested it)so it didn;t give good results. (b) same with prefetching it didn't show good result in current scenarios  and was not as efficient as others ; this might be because in the currect scenario extra loop for prfetching and explicit prefetching call might be expensive ; Please add your views why it did;t come out to be as efficient as other (make clear its observation and the actual reasons are not checked). (c) The best results we got when we either don;t do anything i.e. default or when we  arranged the data in factor of cache line or when we aligned the data structure . (I) here the most surprising result is that in 03 build even if we don't rearrrange and aligngn data or data structure it comes to top or( in list of top efficient results)in terms of efficiency , which suggest compiler does amazing things if the data is sequential like as per my assumption (note make clear its assumption) like vectorization, working on fields withing structure instead of struct as a whole and other memory layout and data access pattern optimizations. Not the best result we go is when we arranged the data in factor of the cacheline such that max number of data can fit in cache line full, also we used array instead of vector and aligned it to cache line  and instruct the compiler to unroll  the number of loop which  is equivalent to the number of data in cache line. (3) I want you to start withMarketData struct and improve step by step explaining the itigrities of cache optimizations.



perfect; this is the most optimized result so far; I would like to create a article for blogging sites regarding ; cache optimization focusing on prefetching ; note I have earlier published a article on ; cache optimization focusing on data alignment where I have shown how we can achieve cache optimization by reordering (if required even explicit aligning) of data and then further aligning the data structure or the container that the data will be stored and finally by using unrolling loop such that max data can fit in the cache in a single iteration of aligned container. This will be the second article on this series which I want to focus on data which can;t be aligne as they are not stored in a contiguous storage space ; So one of the technique for that is prefetching; that we discussed in details and also I have done extensive benchmark testing and also optimized during the process by reordering the data i.e. realaigning + prefetch combination for data which are not stored in contiguous storage to optimize the processing by making it cache friendly. So pleas put a gist on this in the beginning of the article . start with why prefetching where please explain the limitation of cache optimization by data and container alignment when data is not stored in contagious space; the use cases where prefetching can be used. explanation of prefetch function including non-blocking nature and other things including  (prefetch distance, compiler support) with example where ever required ; example of the order processing of linked list as you provided earlier with the same structure i.e. struct{int orderID, double price, int quantity};  small explanation; improved over  it by using frefetcher ; with example including explanation how it works ; why first prefetch is before loop and later/ rest inside loop; non-blocking nature and taking care or preventing prefetching too close etc that we discussed earlier; further improvement; we will reorder this struct to struct {long price, int orderID, int quantity}; which will make it more efficient as it will be multiple of 64 and 4 instances can fit in a cache line; provide explanation of benefits; than we will prefetch in batch i.e. we will first align or reorder data such that it takes minimum space and if possible (non hard and fast rule) multiple of cache line size ; than calculate the number of element can can fit in cache like ; than so batch prefetch equivalent to the size we calculated; provide the example (which we already discussed and tested in  our discussion). conclude the article. 
